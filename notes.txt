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
git clone https://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@github.com/tejaswini29598/java_dsa
Minimum one branch is created when we create a repository
steps and commands:
place a document file in the java_dsa folder
here i placed Notes.txt
1. ask the git to list down all the files that nedd to be pushed(uploaded)

$git add path
$git add C:/learning/java_dsa
$git add .

2. push (upload)
$ git push origin main
$ git push (Always pushes to main branch)

3. Ask the git to create a secured object in which all the files to pushed are copied
$git commit -m "java dsa notes added"

To check the status of the repository
$ git status

now open the java_dsa in vs code

To create project in eclipse:
file -> new -> project -> java Project
in the dialogue box (new window)
de-select the module.java check box
enter the project name(practice) and click finish

now in explorer, expand the project folder
now right click  src folder -> create -> new -> package
give the package name "day1"

right click  "day1" in explorer (under src folder), create -> class
class name "HelloWorld" 

Primitives types in java
    Numeric:
	  number only
		byte
		short
		int 
		long
	  number with precision/ accuracy
	  float
	  double
	Char
    Boolean	
ARITHMETIC OPERATORS:
+ - * / %

// 11/06/25 //

All the operators take 2 operands/inputs
Hence, All are binary operators
The expression is written using "INFIX" notation
55 + 5
inputs are numbers
output is also a number
5+8/9 The division must be evaluated first because of the BODMAS rule
All arithmetic operators hava left to right associtivity
The "INFIX" expression is what we uses but it will be first converted to "POSTFIX" expression and only then it will get evaluated

int num=45;
00000000 00000000 00000000 00101101 //It is decimal to binary conversion how the 45 number is stored in memory

int num= -45;
00101101 // it is the binary value of the 45
11010010 // 1's compliment
11010011 // 2's compliment
now -1 * 2(7) + 1* 2(6) + 1 * 2(4) + 3
-128+64+16+3
-64+19
-45

float num = 5.5; // it is considered as double
therefore float num =5.5f; // considered as float

C++ inherited C

sum = 5 + 5.5;
when the expression has different types of values , then the lower type value will be changed to higher type
this is because the data must not be lost
-----------------------------------------------------------------------

Relational Operators:
> < >= <= != == 
input has numbers
output is Boolean
All are binary operators
used with infix notation
has lesser precedence than arithmetic operators
has higher precedence than logical operators

for i from 1 to n do:
for(int i=1;i<=n;i++)
  or for(int i=1;i<n+1;i++)

(10,40) //closed interval from 10 to 40
(20,30) //open interval from 21 to 29
(35,65) //right open interval from 35 to 64

//assembly language is stored in .esm

i=10;
j=5;
i++; j--;
a[i] =b[j];
b[j]--;

i=10;
j=5;
a[++i] =b[--j]--;
---------------------------------------------------------

logical operators
& &&  | || !
input has boolean 
output is Boolean
All are binary operators except !
used with infix notation
has lesser precedence than arithmetic operators and relational operators
has higher precedence than assignment operators

All the programming files are stored in secondary memory(disk)
files are loaded using "MACROS"(preprocessive directives (#include))
.(dot operator) //left to right associtivity
object.field 
--------------------------------------------------------
java program structure  SUN Microsystems (Standford University Network Microsystems)
oops: abstraction,polymorphism,inheritance,encapsulation
Disadvantages of C++:-
1.main() must be global function
2.global functions were allowed, thus the solutions(apps,software) created with neither procedural or object oriented
3.global variables are still allowed in C++
4.files are loaded using macros and stored till end of the program
5.pointers are always a mess to many programmers
6.The onus(responsibility) of creating and deleting objects in the heap is on programmer
7.the inheritance is by default private which makes the accessing the inherited properties is very difficult. In java it is public inheritance
8.Multiple inheritance creates a solution which is low cohensive
9.The operator overloading concept can be used to just Implementanything which is necessary
10.The compiler created object file which is environment(OS) restircted/dependent/specific.
11.Handling run time errors is difficult
12.objects can be created in stach area as well

In java:(The Disadvantages of C++ have the solution in Java)
1.No global functions, All are only methods (methods vs functions)
Strict object oriented solution.Therefore no concept of global variables
2.signed and unsigned removed thus the primitive datatypes are simplified.
3.libraries can be loaded and used dynamically(no pre process)
4.pointers are abstracted and users are given references.
5.All objects are created in heap only
6.array is an object in java
7.creating object is the only job the programmer does. object deletion is automated with the concept of GARBAGE COLLECTION.
8.the inheritance is by default public thus doesnot make implementation very easy
9.no multiple inheritance
10.all classes are always high cohensive
11.the only operator can be overloaded is + and only for string concatenation
12.The complier creates a byte code which is environment(OS) independent
13.handling runtime errors is easy via exception handling
14.friend concept is removed thus no more ambiguity and complexity in classes
-----------------------------------------------------------------------------------
Different stages of a program
C++ is fast than java during runtime and python is the slowest among all
The code area has the bytecode i.e .class files
static/class vars are stored in GDS
local vars and function parameters ,return address and method address(linkage) are stored in stack area
all objects(instance variables) are stored in heap(dynamically allocated memory)
The creation of objects are done only in runtime and the memory allocation is done also in runtime(dynamic runtime or memory allocation) and in compile time it thinks can i allocate the memory
----------------------------------------------------------------------------------
git add .
git status
git commit -m "assignments file added and notes updated"
git push
------------------------------------------------------------------------------------
1z0-829/1z0-830 java certificaitons 15000/-
study official documentations
NPTEL certificaitons
c-DAC govt of india
---------------------------------------------------------------------------
No function overloading in python
cases of writinig the code(pascal,snake,camel)

//12/6/25 LG Placement exam//

//13/6/25//
void ,static methods

When an object is created during the runtime , first the control goes to declarative statement, secondly it goes to instance initializer block(un-named block). If it is present , then it goes into the respective constructor.
All local variables in java are not initialized until it is initialized by the programmer. Thus the local variables will be empty if they are not initialized. the first assignment to the local variable is its initialization.
Unlike the local variables, the instance variables and the static(class) variables have default values.
byte,short,int and long instance variables hava 0 as the default values
float - 0.0f , double - 0.0
boolean instance or static variable - false
and if the instance or static variable is a reference type, then its default value will be null (ex:String)

The super() in the constructor will make call to immediate parent class constructor and this call happens right are PROLOG of the child class constructor.
We can optionally pass args to super(). However in such a case

without the input statements all the classes of java.lang are always automatically loaded..
The System.in,System.out,System.err are inside the java.lang package and here in,out and err are the static reference variables of the System class
public final class System{
public static final PrintStream out; ---It is the declaration of the out
static{
	out=new PrintStream();
}
}

final variable:
A variable once it is initialized(first assignment) cannot be muted.Thus final variables are read only variables. A final variable can be both static and non-static
A final class cannot be inherited/extended and a final method is one which cannot be overriden in the derived class


1.check if the given positive integer is a perfect square
2.exam result percentage
3.Tax calculation problem
i/p data :name of the employee,basic salary
HRA 15% of basic if employee lives in cosmopolitian city, urban city 10%

//14/6/25//
always use single-responsibility principle because using 2 problem solutions at a time ,it will consume more time 
JVM-Most important program in JRE,SM,MM,GC(Garbage Collector),BV,LL-all together work under JRE
1. public static void main(String[] args):-
In java main() called by OS(JVM) and it doesnot return any value thats why it is void 
Static - the main method belongs to the class itself, rather than to any specific object of that class.
public because it is called by the JVM to access the member of the class in some other package
java is the parent most package in java and Object is the parent most class in java

2. Why constructor has same name as class name and do we hava a return type of java and does not it contain void?
Constructors have the same name as the class for clear identification and implicit invocation during object creation.The constructor has no return type and the constructor is implicitly void always

The threads are nothing but process which run inside the process simultaneously and it is a light-weight process
A process is a program in execution, meaning it's an active entity running on a computer. It has its own memory space, resources, and can't directly share these with other processes without specific mechanisms

Data structure:-
Storing data and also arranging/orgranizing it in memory in so specific way to archive some efficiency(space or time or simplicity) is data structure

1.find sum of the series 1-n+n2-n3...n terms 0<=n<=9 ,1 <=m<=25
2.find sum of odd digits of a number
2345=8(3+5)
3.find sum of even placed digits of a number
9128735=12(1+8+3)
91827364=10(1+2+3+4)
4.second largest and second smallest
consider an array of 5 elements for example, 4 5 3 2 1
here the second largest will be 4 and second smallest will be 2
sort the elements by Arrays.sort(); now it will become 1 2 3 4 5
consider for loop to make iterations
in for loop do the iterations upto n elements or n-1

5. Find sum of Odd placed Even Digits in a number. 
Note: You can make other 3 combinations for the above program.
6. Find smallest/biggest digit in a number.
7. Find sum of 1st and last digits in a number.
8. Find nth placed digit in a number
9. Count number of Prime digits in a number
10. Count number of composite digits in a number.
-----------------------------------------------------------
1. Write a program to print Right angled TRiangle of N lines.
2. Write a program to print Square of N lines.
3. Write a program to print Hollow Square of N lines.
4. Write a program to print X shape of N lines.
5. Write a program to print X shape inside a hollow square of N lines.
6. Write a program to print Hollow Benzene Ring of N lines.
Arrays:-
An array is a DS in which the elements of the array are stored in continous memory locations(There is no gap between 2 consecutive elements in an array).
All elements of an array are of the same DATATYPE(same size).
Array in java is an object because the objects has the array itself and also the length variable in it.
Once the size of an array is fixed, it cannot be changed.
To delete an array ,just make the reference null
It is a memory inefficient datastructures ,time efficient and its lookup is O(1)
simple and primary data structure
Creating:
int array[10]; //error
int[] array = new int[size];
int[] array =new int[5]{1,2,3,4,5};//error
int[] array=new int[]{1,2,3,4,5};
int[] array ={1,2,3,4,5};

--------------------------------------------------------------------------------------------------------
WEEK-2
// 16/6/25 //

CONSTRUCTORS:
*It is called/invoked always implicitly (by the JVM) as soon as an object is created(Objects get memory allocation,that means objects reference values is created).
*The object must have same name as that of the class so that the compiler/JVM knows which of the non static methods in the class are the constructors.
*We can define more than one constructor for the class, thus all the constructors must have the same name and this onset is called as "function overloading".
*The job of the constructor is to initialize an object.
*A constructor cannot return a value ever. Thus its return type is always void. Now something which is always, in  programming must be implicit, because it is always well known. thus mentioning the returnn type for a constructor becomes redundant and hence there must be no return type to a constructor.
*A constructor cannot be static because a constructor is working for an object and it is always has "this". If it is static it should be work for class and not for the object.
* Constructor is usually(99% of the cases) is public.however,they can be private also.
*Constructor cannot be final because all constructors are always final by nature i.e suppose the constructor is overriden in the sub class,and we create an object of the base class, the overriden constructor in the subclass becomes always unreachable.
*The constructor cannot be overriden 
*Constructors cannot be abstract(becuase the abstract methods are not declared but defined) becuase first of all a class choose instance method is abstract its object cannot be created. Further, even if the constructor is defined in the derived class, we know it is unreachable.
Ex: Assume there is a class named "Flight"
Filght(){

}
Flight(String code){

}
main(){ //assume this is the main method
Flight flight = new Flight(); // In this it calls the zero argumented constructor is called, this is called as "STATIC BINDING/COMPILE TIME BIDING/EARLY TIME BINDING"(it decides which function should be called/invoked at the compile stage).
}

FUNCTION OVERLOADING:
*It is the compile time(static/early) bindng/polymorphism which of the overloaded methods must be called is decided by the compiler.
*The overloaded methods if have the same arguments list but different return types then it is an error, because the change must be present at prologue and if the change is only present at apilogue.
*The overloaded functions/methods must differ in their argument list either by number of arguments or datatypes of the arguments or if incase if both the number of arguments and their types are the same the the order must be different.

RELATIONS IN OOPS:
the diagrams that will show the relations called "UML Diagrams" and the diagrams which shows the entry and exit loops and conditions are called "Cyclomatic diagrams"
1.Generalization(inheritance)- "is-a" type of relationship
2.Association - "has-a" part of
--Aggregation (weak or optional association)
--Composition(Strong association)

*Inheritance: suv is a car is-a vehicle
*Aggregation: When the whole object existance is independent of the part object then it is aggregation. When the part object(containee) and the whole object(container) can exist independent of each other.
*Composition: when the whole object existence is dependent on the part of the object existance. When the containee and container cannot exist independent of eachother.
Real life example

why the main() method is static?
definition means the data defined between{ }

ABSTRACT CLASS:
* A class which has at least one abstract method must be marked as abstract
* A class having all methods defined can also be abstract.
* A class having all methods abstract(Except constructors) is said to be 100% abstract
* The derived class which inherits an abstract class can be a concrete class itself doesnot declares any abstract method.
* If the derived class fails to define anyone of the abstract methods of the parent class then it itself must be marked as abstract
* An abstract class can still be used via its static memebers
-----------------------------------------------------------
no super keyword in c++ instead we use ::
-----------------------------------------
create a class to which only one object can be created:
1.for that we have to make all the constructors private but the User can create only one object inside the function
2.The user can access the method when it is public static
3.final A1 a1 = new A1();

public class A1{

}
public class User{
	A1 a1= new A1();
	A1 a2 =new A1();
}
Ex2:
 
//Create a class to which only one onject can be created:

public class A1 {

}
public class User {
	A a1 = new A();
	A a2 = new A();
}


import java.util.Scanner;

class Person {
    private int id;
    private String name;
    private char gender;
    private String location;
    private static Person person; //person is the reference to the Person
    
    private Person() {
        System.out.println("Person object is created");
    }
    
    public static Person createPerson() {
        if (person == null) {
            person = new Person();
        }
        return person;
    }
    
    public void setPerson(int id, String name, char gender, String location) {
        this.id = id;
        this.name = name;
        this.gender = gender;
        this.location = location;
    }
    
    @Override
    public String toString() {
        return "Person Details = Id:" + id + ", Name:" + name +
         ", Gender:" + gender + ", Location:" + location;
    }
}

public class Singleton {
    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);
        Person person1 = Person.createPerson();
        person1.setPerson(101, "nithin", 'm', "mysuru");
        System.out.println(person1); // System.out.print(person.toString());
        
        Person person2 = Person.createPerson();
        System.out.println(person2); // System.out.print(person.toString());
        person2.setPerson(102, "aadya", 'f', "mysuru");
        System.out.println(person1); // System.out.print(person.toString());
    }
}


//17/6/25//
*which string objects in java are not stored in string pool(String pool is a storage space in the Java heap memory where string literals are stored)
...The string literals which stored with new keyword it wont be stored in string pool

//Orange partition
n=9 [18,36,5,79,50,65,30,15,33]
i=0 
j=0 
pivot =33
n=7 [15,23,5,30,40,50,55]
n=6 [50,40,35,30,20,15]


The packages only have code but in the folders we have different formats of files
The public members of the class are accessible in any other package

Function Call STACK:
...The intermediate results are stored in accumulator

IR: Instruction Register --- holds address of the current instruction that is running
PC: Program Counter ----holds address of next instruction to be executed
SP: Stack Pointer --- holds address of the top frame in the stack
FP: Frame Pointer --- Holds address of the frame of the funciton which currently running
Frame:----Memory allocated to a function during runtime
Contents of the Frame:
local variables: The default value of the local variable is NULL until it is initialized and it be known at compiletime,the default values are only available for static and instance variables
function parameter:The value will be known at the runtime
Function addresses: Called function addresses
Return address
when stack  Pointer and frame pointer is null that is the end of the program . This mechanism is designed by Dennis Ritchie
main(String... args){  //main frame is created first
   //args is the reference to the String array
    String s= new String("Hello"); // s is the reference to the string
    print("I am at home");
    A();//function call statement
    print("I am back home");
}
A(){
    int num=10;
     print("I am at home");
    B(45);
    print("I am back home");
}
B(int num){
 print("Hello world");
}


//18/6/25//
Searching,sorting algorithms:
CRUD Opearations(5):
1.File i/p
2.JDBC(Mysql or MongoDB)
3.Hibernate(ORM)
4.SpringBoot(Postman-to test the backend)
Frontend
5.HTML/CSS/JS
6.Reactjs
7.Bootstrap
8.Authenticaiton
9.Multiple entities (More than one tabels in the database)

0! =1 (factorial of zero is 1)
n!=n×(n−1)!
1!=1×0!
⇒1=1×0!
⇒0!=1

Linear search(sequential): O(n)
Given a list/array,we have to search for an element.
Count the frequency of an element (number of occurances).
Find the biggest element in an array
Find the 2nd smallest element in an array
Fing biggest and smallest elements in an array
Replace the every occurance of x with y in an array
Remove the spaces or the value -1 in an array
O(n):
1.Usually used to find the WCE of an algorithms
2.It finds the efficiency in terms of N, where N is the size of the i/p list.Thus it depends on N .
3.We can also find BCE and ACE as well
4.Its job is not to give the exact efficiency but to reveal the order in which the efficiency is.Thus we must remove the smaller chucks of value and also the constants.

Best case efficiency(BCE)  O(1)
ACE O(n)
WCE O(n)

Take the i/p zise from the user.
create the array with user given size.
Read the i/p data for the array.
Now search an element
Print the o/p - position where the element is found (1st occurance)

Problem:
ArrayList javacollection
Project Game 
     Game
     Player
Player
  id,name,points,playerCount (static)
  
define 2 classes:
Player -pojo class
PlayerOperation - CRUD 
 Menu:create/add player , modifyPlayer, deletePlayer, listAllPlayers,
Main()-- Menu based (do-while switch case)



OLTP(Online Transactional Processing)
OLAP(Online Analytical Processing)

inside instance methods we can access static methods

Interface: Type independent and abstract

Binary Search:
*Auto boxing(the int value is converted into INTEGER Object in the INTEGER wrapper class and all wrapper classes are placed in java.lang) and auto unboxing
The fastest algorithm
Pre-requiste: The i/p list must be sorted and we must also know the order of sorting
first we go to exact mid element 
if it is even number of elements it is easy,but it is odd number of elements it is not easy(we reduce the search area by 50% percent).
Example:
number of searches:
linear search       binary search
10,00,000            10,00,000
9,99,999            5,00,000
9,99,,998            2,50,000
9,99,997            1,25,000
9,99,996            62,500
9,99,995            31,250
9,99,994...          15,525.... 1000,500,250,125,62,31,15,7,4,3,2,1
why the iterations is not visible in binary search?
The amount of area is decreased and that decrease we can predict but cannot define it 
Best case efficiency --O(1) (at mid position)
Finding Worst case efficiency in binary search:
Assume it has  X  number of iterations
number of elements in iteration:
N      N/2 N/4 N/8  .......................... 8    4     2     1
2**(x-1)                                         2**3 2**2 2**1  2**0
2**(x-1) =N  ,N is the number of elements in the iterations
2**(x) = N 
x= log(N)
x=y-z
x=y+z 
x/y =z 
y=x/z
in loop low<=high---when low becomes equal to high it means we became at the last element of the iteration 
low<high---it prints that There is a chance of the very first element and last element is not found

for all sorting techniques:
  for i from 0 to n-1:
      for j from 0 to n-i-1 do:
         compare consecutive elements
            swap
//assume array elements 20
public void bubbleSort(int[] array){
    for(int i=0;i<array.length-1;i++){ //here 20-1=19 ,therefore i<18
        for(int j=0;j<array.length-i;j++){
          if(array[j]<arr[j+1])
             swap(array[j],array[j+1]);
        }
    }
}

Best case scenario for almost all sorting techniques are the input array is already sorted(almost sorted)
Best case efficiency : O(n2)
Worst :O(n2) 
worst case scenario for almost all sorting techniques is the input array is already sorted(almost sorted) but we are sorting in reverse order
Bubble Sort:
Unsorted array and we will get the sorted array at the end
Pesimistic sorting technique
O(n)
number of swaps is unpredictable
public void bubbleSort(int[] array){
     boolean sorted =true; //assume the input array is sorted
    for(int i=0;i<array.length-1;i++){ //here 20-1=19 ,therefore i<18
        for(int j=0;j<array.length-i;j++){
          if(array[j]<arr[j+1]){
             swap(array[j],array[j+1]);
             sorted=false;
          }
          if(sorted)
             break;
        }
    }
}
for optimized bubble sort
BCE O(n)
WCE(n2)

5 4 3 2 1
4 3 2 1 5  4 swaps
3 2 1 4 5  3
2 1 3 4 5  2
1 2 3 4 5  1
if the i/p size is 5 then the number of swaps is 10
n*(n-1)/2= 5*(5-1)/2 = 5*4/2=10
(n-1)(n-1+1)/2  = (5-1)(5-1+1)/2 = (4)(5)/2=10

for all sorting techniques:
  for i from 0 to n-1:
      for j from 0 to n-i-1 do:
         compare consecutive elements
            swap
//assume array elements 20
public void bubbleSort(int[] array){
    for(int i=0;i<array.length-1;i++){ //here 20-1=19 ,therefore i<18
        for(int j=0;j<array.length-i;j++){
          if(array[j]<arr[j+1])
             swap(array[j],array[j+1]);
        }
    }
}

Best case scenario for almost all sorting techniques are the input array is already sorted(almost sorted)
Best case efficiency : O(n2)
Worst :O(n2) 
worst case scenario for almost all sorting techniques is the input array is already sorted(almost sorted) but we are sorting in reverse order
//assume elements are 20
public void bubbleSort(int[] array){
     boolean sorted =true; //assume the input array is sorted
    for(int i=0;i<array.length-1;i++){ //here 20-1=19 ,therefore i<18
        for(int j=0;j<array.length-i;j++){
          if(array[j]<arr[j+1]){
             swap(array[j],array[j+1]);
             sorted=false;
          }
          if(sorted)
             break;
        }
    }
}
for optimized bubble sort
BCE O(n)
WCE O(n2)





Selection Sort:
         4 6 4 1 2 9 10 6
  index: 0 1 2 3 4 5 6  7
small =4
index =0

Insertion Sort (Decrease and Conquer):
Optimistic sorting technique
why Insertion sort has better efficiency in the worst case when compared to bubble sort?
..
23  11  3 13  7  5  29  17  23 //length=9
final element :23
here we shifted no swaped
now
11 23
3 11 23
3 11 13 23 
3 7 11 13 23
3 5 7 11 13 23 
3 5 7 11 13 23 29 - here zero swap so increment
3 5 7 11 13 17 23 29 
3 5 7 11 13 17 23 29 23
3 5 7 11 13 17 23  23 29 

public void insertionSort(int[] array){
    for(int i=1;i<array.length;i++){ //run through the elements unsorted array
        element=array[i];
        int j=i-1; //j is the index of the element in the sorted array in which we have to compare the element in the unsorted array
        while(j>=0 && element <array[j]){ //shifting the element in sorted
            array[j+1]=array[j];
            j--;
        }
        array[j+1] =element;
    }
}
Best case scenario : already sorted array
BCE -O(n)
WCE -O(n2)
average -O(n2)

Quick Sort:



*Depth/height of the tree ,we can insert 2**(h)-1 ,if the actual number of nodes are less than 2(h)-1 it is imbalanced tree
AVL TREE:


//19/6/25//
Problem solving in Guvi HCl portal 
Bitwise Operators:
& | ^ >> << ~
byte num1 = 29;//00011101
byte num2 =18;//00010010
int result = num1 & num2;
System.out.println("Num1 and Num2" +result);
int result1 = num1 & num2;
System.out.println("Num1 and Num2" +result1);
int result2 = num1 | num2;
System.out.println("Num1 and Num2" +result2);
int result3 = num1 ^ num2;
System.out.println("Num1 and Num2" +result3);
int result4 = num1 >> num2; //right shift
System.out.println("Num1 and Num2" +result4);
int result5 = num1 << num2; //lef shift
System.out.println("Num1 and Num2" +result5);
int result6 = ~ num2;
System.out.println("Num2 " +result6);
Problems on Bitwise operators
1.Find the nth bit of an int variable
2.flip all the bits of a variable and print its value.
3.Masking
-------------------------------------------------------------------
INTERVIEW SKILLS:
MCQ TEST:
MCSR(Multiple choice single response):
1. Direct method
2.Indirect method
MCMR:
1.Negative marking

Problem: //permutation
input num =8476273
output num =the next biggest number (8476327)
//use this problem using recursion and also can iteration
//write a four digit number in that any digit should repeat twice only . it is Karprekar constant problem
i/p: 3421
step1 : 4321 //decreasing
1234 //increasing
4321-1234 =3087 //difference between biggest and smallest
step2:
i/p: 3087
8730
0378
8730-0378=8352
i/p:8352
int num =scanner.nextInt();
String inputNum =String.valueOf(nums);
char[] numArray =input.toCharArray();
Arrays.sort(numArray);
inputNum = new String(numArray);
int small = integer.ParseInt(inputNum);
StringBuilder sb = new StringBuilder(inputNum);
sb.reverse();
inputNum = sb.toString();
int bigNum = Integer.ParseInt(inputNum);
int difference = bigNum - small;


---------------------------------------------------------------
DAY9 FRIDAY 20-06-2025 (absent)

STEPS TO DOWNLOAD MYSQL:

Google Search: Download MySQL
Click on Link:   mysql.com/downloads
-> MySQL Community GPL Downloads 
-> MySQL Installer for Windows 
-> No thanks start my download
Note: Download the Latest version (8.0.3) and the Bigger Sized File (330 MB or so)

Steps to Install MySQL:
Choose Setup type as Full -> Click Next
MySql Server + Mysql WorkBench + MySql Shell (Drag all these to right)
Do not select the check box -> Click Next
Click on Execute (Make sure that all 3 Apps are visible in "Installation") -> Click Next
Type and Networking -> Click Next
Product Config -> click Next -> Port Number is shown -> Click Next
Use Strong Password -> Click Next
Set the Password (Remember it) -> Click Next
Windows Service -> Click Next
Server File Permissions -> Click Next
Apply Config -> Click Execute
Successful Message -> Click Finish 
Product Config -> Click Next
Installation Complete -> Click Finish
Workbench Runs
Go to MysQl Folder -> server folder -> bin (Add path to Environment Vars)

cmd -> mysql --version

mysql -u root -p   (To force the mysql to prompt for password)

show databases;  // run this command
create database db1;
--------------------------------------------------------------
//21/6/25//
if we cant get the version of mysql in command prompt:
Steps:
1. c:/programfiles/mysql/mysql server/bin (copy the path)
2. go to environment variables
3. path->new -> paste the path
now go the command prompt and enter mysql --version (it gives the version of the mysql)

C:\Users\tejas>mysql --version
mysql  Ver 8.0.42 for Win64 on x86_64 (MySQL Community Server - GPL)

C:\Users\tejas>mysql -u root -p
Enter password: *********  (Teju@2903)
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 22
Server version: 8.0.42 MySQL Community Server - GPL

Copyright (c) 2000, 2025, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>  show databases
    -> ;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sakila             |
| sys                |
| world              |
+--------------------+
6 rows in set (0.01 sec)

mysql> create databse training
    -> ;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'databse training' at line 1
mysql> create databse trainingdb;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'databse trainingdb' at line 1
mysql> create databse trainingdb
     ->;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'databse trainingdb' at line 1
mysql> CREATE DATABASE trainingdb;
Query OK, 1 row affected (0.01 sec)

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sakila             |
| sys                |
| trainingdb         |
| world              |
+--------------------+
7 rows in set (0.00 sec)

mysql> USE trainingdb;
Database changed

mysql> create table people(id int primary key auto_increment, name varchar(50) not null, location varchar(50), gender varchar(2), age smallint default(0));
Query OK, 0 rows affected (0.04 sec)

mysql> insert into people(john,kakinada,M,18);
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '18)' at line 1
mysql> insert into people(john,kakinada,'M',18);
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ''M',18)' at line 1
mysql> insert into people('john','kakinada','M',18);
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ''john','kakinada','M',18)' at line 1
mysql> insert into people(name,location,gender) values ('john','kakinada','M',18);
ERROR 1136 (21S01): Column count doesn't match value count at row 1

mysql> insert into people(name,location,gender,age) values ('john','kakinada','M',18);
Query OK, 1 row affected (0.01 sec)

mysql> insert into people(name,location,gender,age) values ('Tom','Rajamundry','M',17);
Query OK, 1 row affected (0.01 sec)

mysql> insert into people(name,location,gender,age) values ('Lila','kakinada','F',18);
Query OK, 1 row affected (0.01 sec)

mysql> select * from people;
+----+------+------------+--------+------+
| id | name | location   | gender | age  |
+----+------+------------+--------+------+
|  1 | john | kakinada   | M      |   18 |
|  2 | Tom  | Rajamundry | M      |   17 |
|  3 | Lila | kakinada   | F      |   18 |
+----+------+------------+--------+------+
3 rows in set (0.00 sec)

mysql> insert into people(name,gender,age) values ('David','M',18);
Query OK, 1 row affected (0.01 sec)mysql> select * from people;
+----+-------+------------+--------+------+
| id | name  | location   | gender | age  |
+----+-------+------------+--------+------+
|  1 | john  | kakinada   | M      |   18 |
|  2 | Tom   | Rajamundry | M      |   17 |
|  3 | Lila  | kakinada   | F      |   18 |
|  4 | David | NULL       | M      |   18 |
+----+-------+------------+--------+------+
4 rows in set (0.01 sec)


-----------------------23/6/25 to 29/6/25 (Project space holidays)-------------------------------------------

// 30/6/25 //
Recursion and Backtracking
>>> Recursion algorithms(Towers of hanoi, fibonnaci series, factorials)
A recursion function is the function that calls itself either directly or indirectly
Structure of a recursive function:
1.Base case:
  The condition under which the function will not call itself again
2.Recursive case:
    The condition under which the function will call itself again with a simpler or smaller input

Types of Recursion:
1.Direct Recursion:
   The function calls itself directly
   Example: Factorial function
   factorial(n) {
       if (n == 0) return 1; // Base case
       return n * factorial(n - 1); // Recursive case
   }
2.Indirect Recursion:
    The function calls another function, which in turn calls the first function
    Example: Two functions calling each other
    functionA() {
         functionB();
    }
    functionB() {
         functionA();
    }
3.Tail Recursion:
    The recursive call is the last operation in the function, allowing for optimization by the compiler or interpreter
    Example: Tail-recursive factorial function
    tailFactorial(n, accumulator = 1) {
         if (n == 0) return accumulator; // Base case
         return tailFactorial(n - 1, n * accumulator); // Recursive case
    }

Advantages:
..Simplifies code for the Problems that have a recursive structure 
..can make code more reliable and easier to understand
Disadvantages:
..Can lead to stack overflow if the recursion depth is too high

Usage:
..Mathematical problems (factorial, Fibonacci)
..Data structures (trees, graphs)
..Algorithms(quick sort, merge sort,binary search)

>>> Backtracking:
It is systematically searches for a solution to a problem among all available options
It is a problem-solving technique that builds candidates for solutions incrementally and abandons candidates as soon as it determines that they cannot lead to a valid solution

Structure of a Backtracking Algorithm:
1.Choose:
   Select an option from the available choices
2. Explore:
   Recursively explore the next level of the search space
3. Evaluate:
   Check if the current solution is valid
4. Backtrack:
   If the solution is not valid, undo the last step and try the next option

How backtracking works:

** Radix Sort **
consider 23,87,11,113,56,48,9,103
now see the digits of the numbers as take 23 in one's place it is having 3 and in ten's place it is having 2
Therefore in 10^0 (1)=3 and 10^1(10)=2
now sort the elements according to 1's place
{011} {023,113,103} {056} {087} {048} {009}
sorting for ten's place
{103,009} {011,113} {023} {048} {056} {087}
sorting at 100's place
{009,011,023,048,056,087} {103,113} therefore the elements are sorted

Pseudo code:
function radixSort(array,N,place) //pass {
   dict = parse of each pair is of key:digit, value:array
   for 0 in array:
    digit = 0/place % 10
    if the key 'digit' not in dict:
      dict[digit] = new arr
    dict[digit].add(0)
   //copy numbers in the dictionary back to array
   i =0
   for group in dictValues:
     for 0 in group:
        arr[i]=0
        i++
}
 function sort(array,N){
    //find the max number in the array
    max = maximum(array,N)  
    iterate base/radix/place = 1,10,100 < max
     radixSort(array,N,place)
    print(array,N)
 }

** Bucket Sort **
the bucket sort technique is used to store the elements in the given range in the buckets 
in other words,  distributing elements of an array into a number of "buckets." Each bucket is then sorted individually(we can use any sorting technique), and finally, the elements are gathered back into the original array in sorted order.


//1/7/25//
Detailed Notes on Recursion:
    1. Definition:
        - Recursion is a method 
          where the solution to a problem 
          depends on solutions to smaller instances of the same problem.
        - A recursive function is 
          a function that calls itself, 
          either directly or indirectly.

    2. Structure of a Recursive Function:
        - Base Case: 
          The condition under which the recursion ends. 
          Prevents infinite recursion.
        - Recursive Case: 
          The part where the function calls itself 
          with a simpler or smaller input.

    3. How Recursion Works:
        - Each recursive call 
          adds a new frame to the call stack.
        - When the base case is reached, 
          the stack unwinds as each function call returns.

    4. Types of Recursion:
        - Direct Recursion: 
          A function calls itself directly.
        - Indirect Recursion: 
          A function calls another function, 
          which eventually calls the first function.
        - Tail Recursion: 
          The recursive call is the last operation in the function. 
          Some languages optimize tail recursion 
          to avoid stack overflow.

    5. Advantages:
        - Simplifies code for problems 
          that have a recursive structure 
          (e.g., tree/graph traversal, divide and conquer algorithms).
        - Can make code more readable and 
          easier to maintain.

    6. Disadvantages:
        - Can lead to high memory usage 
          due to call stack growth.
        - May be less efficient 
          than iterative solutions 
          for some problems.
        - Risk of stack overflow 
          if the base case is not reached or 
          recursion is too deep.

    7. Common Uses:
        - Mathematical computations (factorial, Fibonacci numbers).
        - Data structures (traversing trees, graphs).
        - Algorithms (quick sort, merge sort, binary search).

    8. Example (Factorial):

        ```python
        def factorial(n):
            if n == 0 or n == 1:  # Base case
                return 1
            else:
                return n * factorial(n - 1)  # Recursive case
        ```

    9. Tips for Writing Recursive Functions:
        - Always define a clear base case.
        - Ensure each recursive call progresses toward the base case.
        - Consider the maximum recursion depth and stack limitations.
        - Test with small inputs first to verify correctness.

    10. Recursion vs Iteration:
        - Recursion uses function calls and 
          the call stack; 
          iteration uses loops.
        - Some problems are naturally recursive, 
          while others are more efficiently solved with iteration.

Detailed Notes on Backtracking:
    1. Definition:
        - Backtracking is a general algorithmic technique 
          for solving problems incrementally, 
          by trying partial solutions and 
          then abandoning them 
          if they do not lead to a valid solution.
        - It systematically searches 
          for a solution to a problem 
          among all available options.

    2. Structure of a Backtracking Algorithm:
        - Choose: Make a choice from available options.
        - Constraint: Check if the current choice 
          leads to a valid solution 
          (satisfies constraints).
        - Explore: Recursively explore further choices.
        - Unchoose (Backtrack): Undo the last choice and 
          try another option.

    3. How Backtracking Works:
        - The algorithm builds candidates 
          for the solution step by step.
        - If a candidate fails to satisfy the constraints, 
          the algorithm backtracks to the previous step and 
          tries a different option.
        - This process continues 
          until all possibilities are explored or 
          a solution is found.

    4. Applications:
        - Solving puzzles 
          (e.g., Sudoku, N-Queens problem).
        - Combinatorial problems 
          (e.g., permutations, combinations, subset sum).
        - Constraint satisfaction problems 
          (e.g., crosswords, map coloring).

    5. Advantages:
        - Finds all possible solutions 
          (if required).
        - Can be more efficient than brute-force search 
          by pruning invalid paths early.

    6. Disadvantages:
        - Can be slow for large problem spaces 
          due to exponential time complexity.
        - May require significant memory 
          for deep recursion or large state spaces.

    7. Example (N-Queens Problem):
        ```python
        def solve_n_queens(n):
            def is_safe(board, row, col):
                for i in range(row):
                    if board[i] == col or \
                        board[i] - i == col - row or \
                        board[i] + i == col + row:
                        return False
                return True

            def solve(row, board, solutions):
                if row == n:
                    solutions.append(board[:])
                    return
                for col in range(n):
                    if is_safe(board, row, col):
                        board[row] = col
                        solve(row + 1, board, solutions)
                        board[row] = -1  # Backtrack

            solutions = []
            solve(0, [-1] * n, solutions)
            return solutions
        ```

    8. Tips for Writing Backtracking Algorithms:
        - Clearly define the constraints and base case.
        - Use pruning to eliminate invalid candidates early.
        - Keep track of the current state and 
          undo changes when backtracking.
        - Test with small inputs to verify correctness.

    9. Backtracking vs Recursion:
        - Backtracking is often implemented using recursion, 
          but not all recursive algorithms use backtracking.
        - Backtracking specifically involves undoing choices and 
          exploring alternative paths 
          when a constraint is violated.
N-Queens:
Detailed step-by-step explanation of the provided N-Queens code:
    1. Imports and Class Declaration
        ```java
        import java.util.*;

        public class NQueens {
        ```
        - `import java.util.*;`  
           imports all utility classes 
           (like `Scanner`, `List`, `ArrayList`, etc.).
        - The class `NQueens` contains the main logic.

    2. Main Method
        ```java
        public static void main(String[] args) {
            Scanner sc = new Scanner(System.in);
            int n = sc.nextInt();
            List<List<String>> solutions = solveNQueens(n);
            if (solutions.isEmpty()) {
                System.out.println("No solution");
            } else {
                for (List<String> sol : solutions) {
                    for (String row : sol) {
                        System.out.println(row);
                    }
                    System.out.println();
                }
            }
        }
        ```
        - Reads an integer `n` 
          (the size of the chessboard and number of queens).
        - Calls `solveNQueens(n)` 
          to get all valid solutions.
        - If no solution exists, 
          prints "No solution".
        - Otherwise, 
          prints each solution (each as a list of strings, one per row).

    3. Solving N-Queens
        ```java
        private static List<List<String>> solveNQueens(int n) {
            List<List<String>> res = new ArrayList<>();
            char[][] board = new char[n][n];
            for (char[] row : board) Arrays.fill(row, '.');
            backtrack(res, board, 0, n, new boolean[n], new boolean[2 * n], new boolean[2 * n]);
            return res;
        }
        ```
        - Initializes the result list `res`.
        - Creates an `n x n` board filled with `'.'` (empty cells).
        - Calls `backtrack` to fill the board row by row.
        - Uses three boolean arrays to track columns and diagonals:
        - `cols`: columns with queens.
        - `d1`: "main" diagonals (top-left to bottom-right).
        - `d2`: "anti" diagonals (top-right to bottom-left).

    4. Backtracking Function
        ```java
        private static void backtrack(List<List<String>> res, char[][] board, int row, int n, boolean[] cols, boolean[] d1, boolean[] d2) {
            if (row == n) {
                List<String> sol = new ArrayList<>();
                for (char[] r : board) sol.add(new String(r));
                res.add(sol);
                return;
            }
            for (int col = 0; col < n; col++) {
                int id1 = col - row + n, id2 = col + row;
                if (cols[col] || d1[id1] || d2[id2]) continue;
                board[row][col] = 'Q';
                cols[col] = d1[id1] = d2[id2] = true;
                backtrack(res, board, row + 1, n, cols, d1, d2);
                board[row][col] = '.';
                cols[col] = d1[id1] = d2[id2] = false;
            }
        }
        ```
        - Base Case: If `row == n`, a valid solution is found. 
          Convert the board to a list of strings and add to results.
        - For Each Column: Try placing a queen 
          in each column of the current row.
        - Diagonal Indexing:
            - `id1 = col - row + n` for main diagonals 
            (offset by `n` to avoid negative indices).
            - `id2 = col + row` for anti-diagonals.
        - Safety Check: If the column or 
          either diagonal is already occupied, 
          skip.
        - Place Queen: 
          Mark the board and tracking arrays.
        - Recursive Call: Move to the next row.
        - Backtrack: Remove the queen and 
          reset tracking arrays (undo the move).
        - Continue until all columns are tried.

** Sudoko **
It is a 9x9 grid puzzle where the objective is to fill the grid with digits from 1 to 9 such that no row,column and subgrid contains the same digit more than once.
Step-by-step explanation of your Sudoku solver code:
    1. Imports and Class Declaration
        ```java
        import java.util.*;

        public class SudokuSolver {
        ```
        - Imports all classes from `java.util` (only `Scanner` is used).
        - Declares the `SudokuSolver` class.

    2. Main Method: Input and Output
        ```java
        public static void main(String[] args) {
            Scanner sc = new Scanner(System.in);
            char[][] board = new char[9][9];
            for (int i = 0; i < 9; i++) {
                String[] line = sc.nextLine().trim().split("\\s+");
                for (int j = 0; j < 9; j++) {
                    board[i][j] = line[j].charAt(0);
                }
            }
            solveSudoku(board);
            for (int i = 0; i < 9; i++) {
                for (int j = 0; j < 9; j++) {
                    System.out.print(board[i][j]);
                    if (j < 8) System.out.print(" ");
                }
                System.out.println();
            }
        }
        ```
        - Reads a 9x9 Sudoku board from standard input, one line at a time.
        - Each line is split by whitespace, and 
          each cell is stored as a `char` 
          (e.g., `'5'`, `'.'` for empty).
        - Calls `solveSudoku(board)` to solve the puzzle.
        - Prints the solved board, formatting with spaces between numbers.

        Gotcha: Input must be 9 lines, 
                each with 9 space-separated characters.

    3. Sudoku Solver (Backtracking)
        ```java
        public static boolean solveSudoku(char[][] board) {
            for (int row = 0; row < 9; row++) {
                for (int col = 0; col < 9; col++) {
                    if (board[row][col] == '.') {
                        for (char c = '1'; c <= '9'; c++) {
                            if (isValid(board, row, col, c)) {
                                board[row][col] = c;
                                if (solveSudoku(board)) return true;
                                board[row][col] = '.';
                            }
                        }
                        return false;
                    }
                }
            }
            return true;
        }
        ```
        - Loops through each cell.
        - If an empty cell (`'.'`) is found:
        - Tries all digits `'1'` to `'9'`.
        - If `isValid` returns true, 
          places the digit and recursively tries to solve the rest.
        - If recursion fails, resets the cell to `'.'` (backtracks).
        - If all cells are filled, returns `true` (solved).

        Gotcha: Returns `false` if no valid digit can be placed, 
                triggering backtracking.

    4. Validation Function
        ```java
        private static boolean isValid(char[][] board, int row, int col, char c) {
            for (int i = 0; i < 9; i++) {
                if (board[row][i] == c) return false; // Row check
                if (board[i][col] == c) return false; // Column check
                if (board[3*(row/3)+i/3][3*(col/3)+i%3] == c) return false; // 3x3 box check
            }
            return true;
        }
        ```
        - Checks if placing `c` at `(row, col)` is valid:
        - Not already in the same row.
        - Not already in the same column.
        - Not already in the same 3x3 subgrid.

        Gotcha: The 3x3 box calculation is a common source of confusion:
        - `3*(row/3)` and `3*(col/3)` find the top-left corner of the box (sub-grid).
        - `i/3` and `i%3` iterate over the 3x3 box.

** Permutation of a string **
A permutation of a string is a "rearrangement" of its characters to form a new string or sequence. It essentially means changing the order of the characters while keeping all the original characters present
n!--- for the permutation for not repeated characters

// done codekata problems from 51 - 60 problems


// 2/7/25 //
-  A graph is a non-linear data structure 
   made up of vertices (nodes) and edges (connections). 
   It is used to represent networks 
   like social connections, maps, the internet, 
   dependency structures, and more.
    🔹 Types of Graphs:
        * Directed vs Undirected: Edges have direction or not.
        * Weighted vs Unweighted: Edges may carry weights (e.g., distances, costs).
        * Cyclic vs Acyclic: May or may not contain cycles.
        * Connected vs Disconnected: Whether all nodes are reachable from each other.
        * Simple vs Multigraph: No multiple edges between the same pair vs allowing them.

    🔹 Representation:
        * Adjacency Matrix: 2D array showing connections.
        * Adjacency List: List of nodes with their neighbors (space-efficient).

    🔹 Applications:
        * Shortest path finding (Dijkstra, Bellman-Ford)
        * Topological sort (DAG)
        * Network routing
        * Cycle detection
        * Social network analysis
        * Game AI and puzzles

Notes on graph    
    🔹 Properties of Graphs:
        * Order: Number of vertices (nodes) in the graph.
        * Size: Number of edges in the graph.
        * Degree: Number of edges connected to a vertex.
        * Path: Sequence of vertices connected by edges.
        * Cycle: Path that starts and ends at the same vertex.
        * Connectedness: Whether there is a path between every pair of vertices.
        * Components: Subgraphs in which any two vertices are connected.

    🔹 More Types of Graphs:
        * Complete Graph: Every pair of vertices is connected.
        * Bipartite Graph: Vertices can be divided into two sets, with edges only between sets.
        * Tree: A connected acyclic undirected graph.
        * DAG (Directed Acyclic Graph): Directed graph with no cycles.

    🔹 Graph Representations (Examples):

        * Adjacency Matrix (for 4 nodes):
            0 1 2 3
          0 0 1 0 1
          1 1 0 1 0
          2 0 1 0 1
          3 1 0 1 0

        * Adjacency List:
            0: 1, 3
            1: 0, 2
            2: 1, 3
            3: 0, 2

    🔹 Graph Traversal Algorithms:

        * Breadth-First Search (BFS):
            - Explores neighbors level by level.
            - Uses a queue.
            - Finds shortest path in unweighted graphs.

            Example (Adjacency List):
                Graph: 0: [1,2], 1: [0,3], 2: [0,3], 3: [1,2]
                BFS from 0: Visit 0 → 1 → 2 → 3

            Python Example:
                from collections import deque
                def bfs(graph, start):
                    visited = set()
                    queue = deque([start])
                    while queue:
                        node = queue.popleft()
                        if node not in visited:
                            print(node)
                            visited.add(node)
                            queue.extend(n for n in graph[node] if n not in visited)

        * Depth-First Search (DFS):
            - Explores as far as possible along each branch before backtracking.
            - Uses a stack (can be implemented recursively).
            - The recursive function in graph is Dfs
            Example (Adjacency List):
                Graph: 0: [1,2], 1: [0,3], 2: [0,3], 3: [1,2]
                DFS from 0: Visit 0 → 1 → 3 → 2

            Python Example:
                def dfs(graph, node, visited=None):
                    if visited is None:
                        visited = set()
                    if node not in visited:
                        print(node)
                        visited.add(node)
                        for neighbor in graph[node]:
                            dfs(graph, neighbor, visited)
                            
>>>DFS and BFS 
why scanner.nextLine(); is added before declaration of string like this  Scanner scanner = new Scanner(System.in);
        int n = scanner.nextInt();
        List<Integer> arr = new ArrayList<>();
        scanner.nextLine();
        String secondLine =scanner.nextLine();
// This is done to consume the newline character left in the input buffer after reading an integer with nextInt().
// If we don't do this, the next call to nextLine() will read an empty string
// because it encounters the leftover newline character from the previous input.
int n = scanner.nextInt();   // reads number, leaves \n
scanner.nextLine();          // consumes the leftover newline
String secondLine = scanner.nextLine();  // now reads the actual line

input: 
5
10 20 30 40 50
output:
line = ""   // oops! it's just the leftover \n
10 20 30 40 50

int n = scanner.nextInt();
scanner.nextLine();  // flush the newline
String line = scanner.nextLine();  // correctly reads "10 20 30 40 50"
// This ensures that the nextLine() call works as expected and captures the intended input.
>>>Heap techniques 
32 29 3 4 1 5 6 18 7 20  n=10

// 3/7/25  afternoon:AMCAT exam //

Queue : offer() ,poll(), peek() 
>>peek():
 Returns the smallest element (for a min-heap) or the largest element (for a max-heap) without removing it from the heap.
>> poll()
 Returns and removes the smallest (min-heap) or largest (max-heap) element from the heap.
... peek() → look at the top element
...poll() → remove and return the top element
 minHeap.offer(5);
        minHeap.offer(3);
        minHeap.offer(8);  
minheap:[3, 5, 8]
Index:   0   1   2
Value:   3   5   8

        3        ← index 0
       / \
      5   8      ← indices 1 and 2
heap[i] <= heap[2*i + 1]  // left child (if exists)
heap[i] <= heap[2*i + 2]  // right child (if exists)
For i = 0 (value = 3):
Left child: heap[1] = 5 → ✅ 3 <= 5
Right child: heap[2] = 8 → ✅ 3 <= 8
Heap condition is satisfied.

For i = 1 (value = 5):
2*i + 1 = 3 and 2*i + 2 = 4 → indices out of bounds → no children → ✅

For i = 2 (value = 8):
Same: no children → ✅

SOLID principles:
>> open-close principle(O) , single rule principle(S), liskov substitution principle(L), dependency inversion principle(D), interface segregation principle(I)
>> Liskov Substitution Principle (LSP):
    - Objects of a superclass should be replaceable with objects of a subclass without affecting the correctness of the program.
    - Example: If `Bird` is a superclass and `Penguin` is a subclass, then `Penguin` should be able to replace `Bird` without causing issues in the code that uses `Bird`.
>> Dependency Inversion Principle (DIP):
    - High-level modules should not depend on low-level modules. Both should depend on abstractions (interfaces).
    - Abstractions should not depend on details; details should depend on abstractions.
    - Example: Instead of a class directly instantiating another class, it should use an interface or abstract class to allow for flexibility and easier testing.
>>open-close principle:
open for extension, closed for modification
    - Classes should be open for extension but closed for modification.
    - This means you can add new functionality by extending existing classes without changing their source code.
    - Example: If you have a class `Shape`, you can extend it to create `Circle` and `Square` without modifying the `Shape` class itself.
>> Single Responsibility Principle (SRP):
    - A class should have only one reason to change, meaning it should have only one job or responsibility.
    - Example: A class that handles user authentication should not also handle user notifications. These should be separate classes.
>> Interface Segregation Principle (ISP):
    - Clients should not be forced to depend on interfaces they do not use.
    - This means that interfaces should be small and specific rather than large and general.
    - Example: Instead of having a single `Animal` interface with methods for flying, swimming, and walking, you could have separate interfaces like `Flyable`, `Swimmable`, and `Walkable` so that classes only implement what they need.
Heap:
    - A heap is a specialized tree-based data structure that satisfies the heap property.
    - In a heap, for any given node, 
      the value of the node is either 
      greater than or equal to (in max-heap) or 
      less than or equal to (in min-heap) 
      the values of its children.
    - Heaps are commonly implemented as binary heaps, 
      where each parent has at most two children.
    - Heaps are complete binary trees, 
      meaning all levels are fully filled except possibly the last, 
      which is filled from left to right.

Min-Heap:
    - In a min-heap, 
      the value of each parent node is 
      less than or equal to the values of its children.
    - The smallest element is always at the root.
    - Common operations: 
        insert, extract-min (remove the smallest element), decrease-key.
    - Used in algorithms like Dijkstra's shortest path and Prim's minimum spanning tree.

Max-Heap:
    - In a max-heap, 
      the value of each parent node is 
      greater than or equal to the values of its children.
    - The largest element is always at the root.
    - Common operations: 
        insert, extract-max (remove the largest element), increase-key.
    - Used in algorithms like heap sort and for implementing priority queues.

Priority Queue:
    - A priority queue is an abstract data type where each element has a priority.
    - Elements are served based on priority (highest or lowest), not just the order they arrive.
    - Heaps (min-heap or max-heap) are commonly used to implement priority queues efficiently.
    - Operations: insert (add an element), 
      peek (view the highest/lowest priority element), 
      extract (remove the highest/lowest priority element), 
      change priority.

Summary:
    - Heap is a tree-based structure with heap property.
    - Min-heap: root is the minimum; max-heap: root is the maximum.
    - Priority queue uses heaps to manage elements by priority.

Examples:
.
    Min-Heap Example:
        Consider the following numbers inserted into a min-heap: 5, 3, 8, 1, 2
        The resulting min-heap (as a binary tree) would look like:
                1
              /   \
             2     8
            / \
           5   3
        - The smallest element (1) is at the root.

    Max-Heap Example:
        Insert the numbers 5, 3, 8, 1, 2 into a max-heap:
                8
              /   \
             5     3
            / \
           1   2
        - The largest element (8) is at the root.

    Priority Queue Example (using min-heap):
        Suppose we have tasks with priorities: (Task A, 4), (Task B, 2), (Task C, 5)
        After inserting into a min-heap-based priority queue:
            - The task with the lowest priority value (Task B, 2) will be served first.
        Operations:
            - Insert (Task D, 1): Task D becomes the new root.
            - Extract-min: Removes Task D (priority 1).

    Heap as Array Representation:
        For a heap:        10
                         /    \
                        15     30
                       /  \
                      40  50
        Array: [10, 15, 30, 40, 50]
        - For node at index i:
            - Left child: 2i + 1
            - Right child: 2i + 2
            - Parent: floor((i - 1) / 2)
//4/7/25//
>>>Hash table:
...it is a datastructure that stores key-value pairs.
...uses hash function to compute an index into an array of buckets or slots, from which the desired value can be found.
operations:
...insert,delete,search(all average O(1) time complexity)
...collisions (when two keys hash to the same index) are handled using techniques like chaining(linked list at each bucket) or open addressing (probing for next available slot)

>>>HashMap:
A hash map is a specific implementation of a hash table that maps keys to values in Java.
Hash Table:
    - A hash table is a data structure that stores key-value pairs.
    - It uses a hash function 
      to compute an index (hash code) into an array of buckets or slots, 
      from which the desired value can be found.
    - Operations: Insert, Delete, Search (all average O(1) time complexity).
    - Collisions (when two keys hash to the same index) are 
      handled using techniques like chaining 
      (linked lists at each bucket) or 
      open addressing (probing for next available slot).
    - Hash tables are widely used 
      for implementing associative arrays, 
      database indexing, and caches.

Hash Map:
    - A hash map is a specific implementation of a hash table that maps keys to values.
    - In many programming languages (e.g., Java, C++), "HashMap" is a built-in class.
    - Keys must be unique; values can be duplicated.
    - Not thread-safe by default (e.g., Java's HashMap), but thread-safe variants exist (e.g., ConcurrentHashMap).
    - Provides fast lookups, insertions, and deletions.

Hash Set:
    - A hash set is a data structure that stores unique elements, using a hash table internally.
    - Only stores keys (no associated values).
    - Used to test membership (whether an element exists) efficiently.
    - Operations: Add, Remove, Contains (all average O(1) time complexity).
    - In many languages, "HashSet" is a built-in class (e.g., Java, C#).

Summary:
    - Hash Table: General concept for key-value storage using hashing.
    - Hash Map: Key-value implementation of a hash table.
    - Hash Set: Stores unique elements using a hash table.

Collision Resolution Techniques in Hashing:
    - Collisions occur when two keys hash to the same index in a hash table.
    - Common techniques to handle collisions:
        1. Chaining:
            - Each bucket contains a linked list (or another data structure) of entries.
            - All elements that hash to the same index are stored in the list.
            - Simple to implement; performance degrades if many collisions occur.
        2. Open Addressing:
            - All elements are stored within the hash table array itself.
            - When a collision occurs, the algorithm searches for the next available slot.
            - Methods include:
                a. Linear Probing: Check the next slot sequentially.
                b. Quadratic Probing: Check slots at increasing quadratic intervals.
                c. Double Hashing: Use a second hash function to determine the step size.
        3. Other Techniques:
            - Cuckoo Hashing: Uses multiple hash functions and relocates existing keys.
            - Robin Hood Hashing: Balances probe sequence lengths to minimize variance.
    - The choice of technique affects performance, memory usage, and implementation complexity.

Java Example: Implementing a Simple Hash Table
    Below is a basic implementation of a hash table in Java using chaining for collision resolution:

    ```java
    import java.util.LinkedList;

    class HashTable<K, V> {
        private static class Entry<K, V> {
            K key;
            V value;
            Entry(K key, V value) {
                this.key = key;
                this.value = value;
            }
        }

        private final int SIZE = 16;
        private LinkedList<Entry<K, V>>[] table;

        @SuppressWarnings("unchecked")
        public HashTable() {
            table = new LinkedList[SIZE];
            for (int i = 0; i < SIZE; i++) {
                table[i] = new LinkedList<>();
            }
        }

        private int hash(K key) {
            return Math.abs(key.hashCode()) % SIZE;
        }

        public void put(K key, V value) {
            int index = hash(key);
            for (Entry<K, V> entry : table[index]) {
                if (entry.key.equals(key)) {
                    entry.value = value;
                    return;
                }
            }
            table[index].add(new Entry<>(key, value));
        }

        public V get(K key) {
            int index = hash(key);
            for (Entry<K, V> entry : table[index]) {
                if (entry.key.equals(key)) {
                    return entry.value;
                }
            }
            return null;
        }

        public void remove(K key) {
            int index = hash(key);
            table[index].removeIf(entry -> entry.key.equals(key));
        }
    }

    // Example usage:
    public class Main {
        public static void main(String[] args) {
            HashTable<String, Integer> hashTable = new HashTable<>();
            hashTable.put("apple", 1);
            hashTable.put("banana", 2);
            hashTable.put("orange", 3);

            System.out.println(hashTable.get("banana")); // Output: 2

            hashTable.remove("banana");
            System.out.println(hashTable.get("banana")); // Output: null
        }
    }
    ```

    Explanation:
    - The `HashTable` class uses an array of linked lists to handle collisions (chaining).
    - The `put` method adds or updates key-value pairs.
    - The `get` method retrieves the value for a given key.
    - The `remove` method deletes a key-value pair.
    - The example in `Main` demonstrates basic usage.

In Java, a hash function converts an object (like a String or Integer) 
into an integer value called a hash code. 
This hash code is used to determine 
where to store or find the object 
in hash-based data structures 
(like `HashMap` or your `HashTable`).

How it works:
    - Every Java object has a `hashCode()` method (inherited from `Object`).
    - For built-in types (like `String`, `Integer`), 
    Java provides efficient `hashCode()` implementations.
    - The hash code is usually further processed 
    (e.g., using modulo with the array size) 
    to find the correct index in the underlying array.

Example:
    ```java
    String key = "apple";
    int hash = key.hashCode(); // Generates a hash code for "apple"
    int index = Math.abs(hash) % array.length; // Maps hash to a valid array index
    ```

Key points:
    - Good hash functions distribute keys evenly to minimize collisions.

===



//5/7/25//
Dynamic programming:
It is a problem solving technique used to solve complex problems by breaking them down into simpler subproblems and storing the results of these subproblems to avoid redundant calculations.
key concepts:
1.overlapping subproblems:
  The problem can be broken down into smaller subproblems that are reused multiple times.
2.optimal substructure:
  The optimal solution to the problem can be constructed from the optimal solutions of its subproblems.

How Dynamic programming:
-Memorization (top-down approach):
  in this we start solving from 'n';
  To use the memoization (top-down) approach for the Climbing Stairs problem, you use recursion and store results of subproblems in an array (or map) to avoid recomputation
  Store the results of exprensive function calls and return the cached result ,when the same inputs occur again, usually implemented with recursion and a cache (like a dictionary).
-Tabulation (bottom-up approach):
  in this we start solving from '0'th term of n
  In tabulation (bottom-up dynamic programming), you do NOT use recursion.
Instead, you use loops to fill up a table (usually an array) from the base cases up to the desired value.
  Solve all subproblems first, typically using iteration, and store their result in a table(like an array). Build up the solution from the smallest subproblem
  Example: Fibonacci Sequence
    #Naive Recursive Approach (Inefficient)
        ```python
        def fib(n):
            if n <= 1:
                return n
            return fib(n-1) + fib(n-2)
        ```
        This recalculates the same values many times.

    #DP with Memoization
        ```python
        def fib(n, memo={}):
            if n in memo:
                return memo[n]
            if n <= 1:
                return n
            memo[n] = fib(n-1, memo) + fib(n-2, memo)
            return memo[n]
        ```

    #DP with Tabulation
        ```python
        def fib(n):
            if n <= 1:
                return n
            dp = [0, 1]
            for i in range(2, n+1):
                dp.append(dp[i-1] + dp[i-2])
            return dp[n]
        ```

When to Use Dynamic Programming
    - When a problem can be broken into overlapping subproblems.
    - When the problem has optimal substructure.
    - Common in optimization problems (e.g., shortest path, knapsack, coin change).

Gotchas
    - Not all recursive problems benefit from DP—only those with overlapping subproblems.
    - Space complexity can be high if you store all subproblem results; 
    sometimes you can optimize by only keeping necessary states.

Summary
    Dynamic Programming is a powerful technique 
    for optimizing recursive algorithms 
    by storing and reusing subproblem solutions, 
    making it possible to solve complex problems efficiently.

// 6/7/25 sunday //

//7/7/25 //
Trees:
Preorder , postorder and inorder
Traversal:
    - Preorder: Visit root, then left subtree, then right subtree.
    - Inorder: Visit left subtree, then root, then right subtree.
    - Postorder: Visit left subtree, then right subtree, then root.
    - Level Order: Visit nodes level by level, from left to right.
    - Reverse Level Order: Visit nodes level by level, from right to left.
 Example:
 Take a tree and done traversal:
    1                 preorder:1 2 4 5 3 6 7 (Root, Left, Right)
   / \                Inorder:4 2 5 1 3 6 7  (Left, Root, Right)
   2  3               postorder:4 5 2 7 6 3 1 (Left, Right, Root)
  / \  \              levelorder:1 2 3 4 5 6 7  (Top to Bottom, Left to Right)
  4  5  6  
         \
          7 


//8/7/25//
General Tree - Detailed Notes
    Definition:
    - A general tree is a hierarchical data structure in which each node can have zero or more child nodes.
    - Unlike binary trees, there is no restriction on the number of children a node can have.

    Basic Terminology:
    - Node: Fundamental part of the tree containing data.
    - Root: The topmost node in the tree.
    - Parent: A node that has one or more child nodes.
    - Child: A node that descends from another node (its parent).
    - Leaf: A node with no children.
    - Sibling: Nodes that share the same parent.
    - Subtree: A tree formed by a node and its descendants.
    - Level: The distance from the root node (root is at level 0).
    - Height: The length of the longest path from the root to a leaf.

    Properties:
    - There is exactly one root node.
    - Every node (except the root) has exactly one parent.
    - Nodes can have any number of children.
    - The tree is connected and acyclic.

    Representation:
    1. Parent-Child List:
        - Each node stores a list of its children.
    2. First Child/Next Sibling (Left-Child Right-Sibling):
        - Each node has two pointers: one to its first child and one to its next sibling.
    3. Adjacency List:
        - Useful for representing trees as graphs.

    Operations:
    - Traversal:
    - Preorder: Visit node, then recursively visit children.
    - Postorder: Recursively visit children, then visit node.
    - Level-order: Visit nodes level by level.
    - Insertion: Add a child to a node.
    - Deletion: Remove a node and its subtree.
    - Searching: Find a node with a specific value.

    Applications:
    - File system hierarchies (folders and files)
    - Organization charts
    - XML/HTML document object models (DOM)
    - Game trees (AI decision making)
    - Expression trees in compilers

    Advantages:
    - Flexible structure for representing hierarchical relationships.
    - No restriction on the number of children per node.

    Disadvantages:
    - More complex to implement than binary trees.
    - Traversal and manipulation can be less efficient due to variable number of children.

    Example (Parent-Child List):

    Root
    ├── Child1
    │   ├── Grandchild1
    │   └── Grandchild2
    └── Child2
        └── Grandchild3

    References:
    - Data Structures and Algorithms textbooks
    - Wikipedia: https://en.wikipedia.org/wiki/Tree_(data_structure)

Binary Tree - Detailed Notes
    Definition:
    - A binary tree is a hierarchical data structure in which each node has at most two children, referred to as the left child and the right child.

    Basic Terminology:
    - Node: Fundamental part of the tree containing data.
    - Root: The topmost node in the tree.
    - Parent: A node that has one or more child nodes.
    - Child: A node that descends from another node (its parent).
    - Leaf: A node with no children.
    - Sibling: Nodes that share the same parent.
    - Subtree: A tree formed by a node and its descendants.
    - Level: The distance from the root node (root is at level 0).
    - Height: The length of the longest path from the root to a leaf.
    - Depth: The length of the path from the root to a node.

    Properties:
    - Each node has at most two children (left and right).
    - There is exactly one root node.
    - Every node (except the root) has exactly one parent.
    - The maximum number of nodes at level l is 2^l.
    - The maximum number of nodes in a binary tree of height h is 2^(h+1) - 1.

    Types of Binary Trees:
    - Full Binary Tree: Every node has 0 or 2 children.
    - Complete Binary Tree: All levels are completely filled except possibly the last, which is filled from left to right.
    - Perfect Binary Tree: All internal nodes have two children and all leaves are at the same level.
    - Skewed Binary Tree: All nodes have only left or only right child (left-skewed or right-skewed).
    - Balanced Binary Tree: The height of the left and right subtrees of every node differ by at most one.

    Representation:
    1. Linked Representation:
        - Each node contains data, a pointer to the left child, and a pointer to the right child.
    2. Array Representation:
        - Useful for complete binary trees; for node at index i:
            - Left child at 2i + 1
            - Right child at 2i + 2
            - Parent at floor((i - 1) / 2)

    Operations:
    - Traversal:
        - Preorder: Visit node, then left subtree, then right subtree.
        - Inorder: Visit left subtree, then node, then right subtree.
        - Postorder: Visit left subtree, then right subtree, then node.
        - Level-order: Visit nodes level by level.
    - Insertion: Add a node at the appropriate position.
    - Deletion: Remove a node and restructure the tree if necessary.
    - Searching: Find a node with a specific value.

    Applications:
    - Expression trees (arithmetic expressions)
    - Binary search trees (efficient searching and sorting)
    - Heaps (priority queues)
    - Huffman coding trees (data compression)
    - Syntax trees in compilers

    Advantages:
    - Efficient searching, insertion, and deletion (especially in balanced trees).
    - Simple recursive algorithms for traversal and manipulation.

    Disadvantages:
    - Can become unbalanced, leading to degraded performance (O(n) time complexity).
    - Requires careful implementation to maintain balance.

    Example (Linked Representation):

    Root
    ├── LeftChild
    │   ├── LeftLeftGrandchild
    │   └── LeftRightGrandchild
    └── RightChild
        └── RightRightGrandchild

    References:
    - Data Structures and Algorithms textbooks
    - Wikipedia: https://en.wikipedia.org/wiki/Binary_tree

Binary Search Tree (BST) - Detailed Notes
    Definition:
    - A binary search tree is a type of binary tree in which each node contains a key, and satisfies the following properties:
        - The key in each node is greater than all keys in its left subtree.
        - The key in each node is less than all keys in its right subtree.

    Properties:
    - Each node has at most two children (left and right).
    - All keys are unique (no duplicates).
    - Inorder traversal of a BST yields keys in sorted (ascending) order.
    - The left subtree contains only nodes with keys less than the node’s key.
    - The right subtree contains only nodes with keys greater than the node’s key.

    Representation:
    - Typically implemented using linked nodes, where each node contains:
        - Data (key)
        - Pointer to left child
        - Pointer to right child

    Operations:
    - Search:
        - Start at the root and recursively or iteratively move left or right depending on the key.
        - Time complexity: O(h), where h is the height of the tree.
    - Insertion:
        - Insert a new key by traversing the tree and placing it in the correct position to maintain BST property.
        - Time complexity: O(h).
    - Deletion:
        - Remove a node and restructure the tree to maintain BST property.
        - Three cases:
            1. Node is a leaf: Remove it directly.
            2. Node has one child: Replace node with its child.
            3. Node has two children: Replace node with its inorder successor or predecessor.
        - Time complexity: O(h).
    - Traversal:
        - Inorder: Yields sorted order.
        - Preorder, Postorder, Level-order: As in binary trees.

    Applications:
    - Efficient searching, insertion, and deletion of data.
    - Implementing dynamic sets and lookup tables.
    - Used in databases and file systems for indexing.
    - Building associative arrays and symbol tables.

    Advantages:
    - Average-case time complexity for search, insert, and delete is O(log n) if the tree is balanced.
    - Simple implementation and easy to understand.

    Disadvantages:
    - Can become unbalanced (degenerate to a linked list), leading to O(n) time complexity.
    - Requires additional logic or self-balancing variants (e.g., AVL tree, Red-Black tree) to maintain efficiency.

    Example (BST Structure):

    8
    ├── 3
    │   ├── 1
    │   └── 6
    │       ├── 4
    │       └── 7
    └── 10
        └── 14
            └── 13

    References:
    - Data Structures and Algorithms textbooks
    - Wikipedia: https://en.wikipedia.org/wiki/Binary_search_tree

The recursive function in graph is Dfs

//9/7/25//
AVL Tree Notes (Detailed)
  The height starts from '1'
    1. Definition:
        - An AVL tree is a self-balancing binary search tree (BST).
        - Named after inventors Adelson-Velsky and Landis.
        - For every node, the heights of the left and right subtrees differ by at most 1.

    2. Properties:
        - Balance Factor (BF) = height(left subtree) - height(right subtree)
        - For every node: BF ∈ {-1, 0, 1}
        - Ensures O(log n) time complexity for search, insert, and delete.

    3. Rotations:
        - Used to restore balance after insertions or deletions.
        - Four types:
        a) Left Rotation (LL)
        b) Right Rotation (RR)
        c) Left-Right Rotation (LR)
        d) Right-Left Rotation (RL)

    4. Insertion:
        - Insert as in BST.
        - Update heights and balance factors.
        - If imbalance occurs, perform appropriate rotation(s).

    5. Deletion:
        - Delete as in BST.
        - Update heights and balance factors.
        - If imbalance occurs, perform appropriate rotation(s).

    6. Rotations Explained:
        - LL Rotation: Right rotation on unbalanced node.
        - RR Rotation: Left rotation on unbalanced node.
        - LR Rotation: Left rotation on left child, then right rotation on unbalanced node.
        - RL Rotation: Right rotation on right child, then left rotation on unbalanced node.

    7. Complexity:
        - Search: O(log n)
        - Insert: O(log n)
        - Delete: O(log n)

    8. Applications:
        - Databases, file systems, memory management, and any application requiring ordered data with fast lookups.

    9. Advantages:
        - Maintains strict balance, guaranteeing logarithmic height.
        - Faster lookups compared to unbalanced BSTs.

    10. Disadvantages:
        - More rotations and bookkeeping compared to other BSTs (e.g., Red-Black Trees).
        - Slightly more complex implementation.

    References:
    - "Introduction to Algorithms" by Cormen et al.
    - Wikipedia: https://en.wikipedia.org/wiki/AVL_tree

AVL Tree - Operations
    AVL - Left Rotate Steps:
        1. Identify the node (x) to perform left rotation on.
        2. Let y = x.right (the right child of x).
        3. Set x.right = y.left.
        4. Set y.left = x.
        5. Update heights of x and y.
        6. Return y (the new root of the rotated subtree).

        Example (Pseudocode):

        leftRotate(x):
            y = x.right
            x.right = y.left
            y.left = x
            // Update heights
            x.height = 1 + max(height(x.left), height(x.right))
            y.height = 1 + max(height(y.left), height(y.right))
            return y

    AVL - Right Rotate Steps:
        1. Identify the node (y) to perform right rotation on.
        2. Let x = y.left (the left child of y).
        3. Set y.left = x.right.
        4. Set x.right = y.
        5. Update heights of y and x.
        6. Return x (the new root of the rotated subtree).

        Example (Pseudocode):

        rightRotate(y):
            x = y.left
            y.left = x.right
            x.right = y
            // Update heights
            y.height = 1 + max(height(y.left), height(y.right))
            x.height = 1 + max(height(x.left), height(x.right))
            return x

        
    AVL Tree - Insert Steps:
        1. Start at the root node.
        2. Insert the new key as in a standard BST.
        3. Update the height of each ancestor node.
        4. Calculate the balance factor for each ancestor node.
        5. If the balance factor becomes unbalanced (not in {-1, 0, 1}):
            a) Identify the case (LL, RR, LR, RL) based on the structure.
            b) Perform the appropriate rotation(s) to restore balance.
        6. Repeat the process up to the root if necessary.


        Step 5: Handling Unbalanced Nodes in AVL Tree Insertion

        When the balance factor of a node is not in {-1, 0, 1}, the tree is unbalanced. You need to:

        1. Identify the imbalance type:  
        - LL (Left-Left): Insertion happened 
        in the left subtree of the left child.
        - RR (Right-Right): Insertion happened 
        in the right subtree of the right child.
        - LR (Left-Right): Insertion happened 
        in the right subtree of the left child.
        - RL (Right-Left): Insertion happened 
        in the left subtree of the right child.

        2. Apply the appropriate rotation(s):
        - LL Case: Perform a single right rotation.
        - RR Case: Perform a single left rotation.
        - LR Case: Perform a left rotation on the left child, 
        then a right rotation on the unbalanced node.
        - RL Case: Perform a right rotation on the right child, 
        then a left rotation on the unbalanced node.

            Example (Pseudocode):

            ````plaintext
            if balance > 1 and key < node.left.key:
                // LL Case
                rightRotate(node)
            elif balance < -1 and key > node.right.key:
                // RR Case
                leftRotate(node)
            elif balance > 1 and key > node.left.key:
                // LR Case
                leftRotate(node.left)
                rightRotate(node)
            elif balance < -1 and key < node.right.key:
                // RL Case
                rightRotate(node.right)
                leftRotate(node)
            ````

            Summary:  
            - Detect the imbalance type by comparing the inserted key and the structure.
            - Apply the correct rotation(s) to restore AVL balance.

    Additional Explanation: LR Case (Left Triangle)
        The LR case is a left triangle that needs to be straightened:
            1. Left Triangle Pattern:
            ```
                A (BF = +2)
               /
              B (BF = -1)  
               \
                C
            ```
            - This creates a "zigzag" or triangle pattern going left-right
            
            2. Step 1: Left Rotate B (Straighten the triangle)
            ```
                    A
                   /
                  C
                 /
                B
            ```
            - Now we have a straight line going left-left
        
        3. Step 2: Right Rotate A (Balance the line)
            ```
                  C
                 / \
                B   A
            ```
            - Final balanced tree with C as new root

        Key Insight: LR = Left Triangle → Straighten → Balance
            - Triangle: Must be straightened first (left rotate the left child)
            - Line: Then balanced (right rotate the unbalanced node)

    AVL Tree - Delete Steps:
        1. Start at the root node.
        2. Delete the target key as in a standard BST:
            - If the node has no children, simply remove it.
            - If the node has one child, replace it with its child.
            - If the node has two children, 
            replace it with its in-order successor or predecessor, 
            then delete that node.
        3. Update the height of each ancestor node.
        4. Calculate the balance factor for each ancestor node.
        5. If the balance factor becomes unbalanced (not in {-1, 0, 1}):
            a) Identify the case (LL, RR, LR, RL) based on the structure.
            b) Perform the appropriate rotation(s) to restore balance.
        6. Repeat the process up to the root if necessary.

        Step 5: Handling Unbalanced Nodes in AVL Tree Deletion

        When the balance factor of a node is not in {-1, 0, 1}, 
        the tree is unbalanced. You need to:

        1. Identify the imbalance type:
            - LL (Left-Left): Left child’s left subtree is taller.
            - LR (Left-Right): Left child’s right subtree is taller.
            - RR (Right-Right): Right child’s right subtree is taller.
            - RL (Right-Left): Right child’s left subtree is taller.

        2. Apply the appropriate rotation(s):
            - LL Case: Perform a single right rotation.
            - LR Case: Perform a left rotation on the left child, then a right rotation on the unbalanced node.
            - RR Case: Perform a single left rotation.
            - RL Case: Perform a right rotation on the right child, then a left rotation on the unbalanced node.

            Example (Pseudocode):

            ````plaintext
            if balance > 1 and getBalance(node.left) >= 0:
                // LL Case
                rightRotate(node)
            elif balance > 1 and getBalance(node.left) < 0:
                // LR Case
                leftRotate(node.left)
                rightRotate(node)
            elif balance < -1 and getBalance(node.right) <= 0:
                // RR Case
                leftRotate(node)
            elif balance < -1 and getBalance(node.right) > 0:
                // RL Case
                rightRotate(node.right)
                leftRotate(node)
            ````

            Summary:
            - After deletion, update heights and balance factors up the tree.
            - Detect the imbalance type by checking the balance factor of the node and its children.
            - Apply the correct rotation(s) to restore AVL balance.
            
Red-Black Tree Notes (Detailed)
    1. Definition:
        - A Red-Black Tree (RBT) is a self-balancing binary search tree (BST).
        - Each node contains an extra bit for color (red or black).
        - Ensures the tree remains approximately balanced.

    2. Properties (Red-Black Properties):
        - Every node is either red or black.
        - The root is always black.
        - All leaves (NIL nodes) are black.
        - If a node is red, then both its children are black (no two reds in a row).
        - Every path from a node to its descendant NIL nodes contains the same number of black nodes (black-height).

    3. Rotations:
        - Used to maintain balance after insertions and deletions.
        - Two types:
            a) Left Rotation
            b) Right Rotation

    4. Insertion:
        - Insert as in BST, color the new node red.
        - Fix any violations of red-black properties using recoloring and rotations.
        - May require multiple adjustments up the tree.

    5. Deletion:
        - Delete as in BST.
        - If deleting a black node, fix violations using recoloring and rotations.
        - May require multiple adjustments up the tree.

    6. Balancing Explained:
        - Balancing is achieved by enforcing red-black properties after every insert and delete.
        - Rotations and recoloring are used to restore properties.

    7. Complexity:
        - Search: O(log n)
        - Insert: O(log n)
        - Delete: O(log n)

    8. Applications:
        - Used in many libraries and systems (e.g., C++ STL map/set, Java TreeMap/TreeSet).
        - Databases, memory management, and associative containers.

    9. Advantages:
        - Guarantees logarithmic height.
        - Fewer rotations on average compared to AVL trees.
        - Efficient for insertion and deletion-heavy workloads.

    10. Disadvantages:
        - Slightly slower lookups compared to AVL trees due to less strict balancing.
        - More complex than simple BSTs.

    References:
    - "Introduction to Algorithms" by Cormen et al.
    - Wikipedia: https://en.wikipedia.org/wiki/Red%E2%80%93black_tree

Red-Black Tree - Operations
    RBT - Left Rotate Steps:
        1. Identify the node (x) to perform left rotation on.
        2. Let y = x.right (the right child of x).
        3. Set x.right = y.left.
        4. If y.left is not null, set y.left.parent = x.
        5. Set y.parent = x.parent.
        6. If x is the root, set root = y.
        Else if x is a left child, set x.parent.left = y.
        Else set x.parent.right = y.
        7. Set y.left = x.
        8. Set x.parent = y.

        Example (Pseudocode):

        ````plaintext
        leftRotate(x):
            y = x.right
            x.right = y.left
            if y.left != null:
                y.left.parent = x
            y.parent = x.parent
            if x.parent == null:
                root = y
            elif x == x.parent.left:
                x.parent.left = y
            else:
                x.parent.right = y
            y.left = x
            x.parent = y
        ````

    RBT - Right Rotate Steps: 
        1. Identify the node (y) to perform right rotation on.
        2. Let x = y.left (the left child of y).
        3. Set y.left = x.right.
        4. If x.right is not null, set x.right.parent = y.
        5. Set x.parent = y.parent.
        6. If y is the root, set root = x.
        Else if y is a right child, set y.parent.right = x.
        Else set y.parent.left = x.
        7. Set x.right = y.
        8. Set y.parent = x.

        Example (Pseudocode):

        ````plaintext
        rightRotate(y):
            x = y.left
            y.left = x.right
            if x.right != null:
                x.right.parent = y
            x.parent = y.parent
            if y.parent == null:
                root = x
            elif y == y.parent.right:
                y.parent.right = x
            else:
                y.parent.left = x
            x.right = y
            y.parent = x
        ````

    RBT - Insert Steps
        1. Start at the root node.
        2. Insert the new key as in a standard BST.
        3. Color the new node red.
        4. Fix any violations of Red-Black properties:
            a) If the parent is black, insertion is done.
            b) If the parent is red, there is a violation:
                i. If the uncle is red:
                    - Recolor parent and uncle to black.
                    - Recolor grandparent to red.
                    - Move up to the grandparent and repeat.
                ii. If the uncle is black or null:
                    - If the new node is on the "inside" 
                    (left-right or right-left), 
                    rotate to convert to "outside" 
                    (left-left or right-right).
                    - Perform a rotation on the grandparent (right or left, as appropriate).
                    - Swap colors of parent and grandparent.
        5. Ensure the root is always black.

        Example (Pseudocode):

        ````plaintext
        insert(node):
            standard BST insert, color new node red
            while node != root and node.parent.color == RED:
                if node.parent is left child of grandparent:
                    uncle = grandparent.right
                    if uncle and uncle.color == RED:
                        // Case 1: recolor
                        node.parent.color = BLACK
                        uncle.color = BLACK
                        grandparent.color = RED
                        node = grandparent
                    else:
                        if node == node.parent.right:
                            // Case 2: left-rotate parent
                            node = node.parent
                            leftRotate(node)
                        // Case 3: right-rotate grandparent
                        node.parent.color = BLACK
                        grandparent.color = RED
                        rightRotate(grandparent)
                else:
                    // mirror image of above
                    uncle = grandparent.left
                    if uncle and uncle.color == RED:
                        node.parent.color = BLACK
                        uncle.color = BLACK
                        grandparent.color = RED
                        node = grandparent
                    else:
                        if node == node.parent.left:
                            node = node.parent
                            rightRotate(node)
                        node.parent.color = BLACK
                        grandparent.color = RED
                        leftRotate(grandparent)
            root.color = BLACK
        ``` 

    RBT - Delete Steps:
        1. Start at the root node.
        2. Delete the target key as in a standard BST.
        3. If the deleted node or the node that replaces it is red, simply remove it (no violation).
        4. If a black node is deleted or replaced, fix violations of Red-Black properties:
            a) If the replacement node is red, color it black.
            b) If the replacement node is black (or null), perform fix-up:
                i. While the node is not the root and is black:
                    - If the node is a left child:
                        * Let sibling = parent.right
                        * If sibling is red:
                            - Recolor sibling and parent.
                            - Left-rotate parent.
                            - Update sibling.
                        * If both sibling's children are black:
                            - Recolor sibling red.
                            - Move up to parent.
                        * If sibling's right child is black and left child is red:
                            - Recolor sibling and its left child.
                            - Right-rotate sibling.
                            - Update sibling.
                        * If sibling's right child is red:
                            - Recolor sibling with parent's color.
                            - Color parent and sibling's right child black.
                            - Left-rotate parent.
                            - Set node to root.
                    - If the node is a right child: (mirror above)
                ii. Color node black.
        5. Ensure the root is always black.

        Example (Pseudocode):

        ````plaintext
        delete(node):
            standard BST delete
            if deleted node was red or replacement is red:
                // No fix needed
                return
            while node != root and node.color == BLACK:
                if node == node.parent.left:
                    sibling = node.parent.right
                    if sibling.color == RED:
                        sibling.color = BLACK
                        node.parent.color = RED
                        leftRotate(node.parent)
                        sibling = node.parent.right
                    if sibling.left.color == BLACK and sibling.right.color == BLACK:
                        sibling.color = RED
                        node = node.parent
                    else:
                        if sibling.right.color == BLACK:
                            sibling.left.color = BLACK
                            sibling.color = RED
                            rightRotate(sibling)
                            sibling = node.parent.right
                        sibling.color = node.parent.color
                        node.parent.color = BLACK
                        sibling.right.color = BLACK
                        leftRotate(node.parent)
                        node = root
                else:
                    // mirror image of above
                    sibling = node.parent.left
                    if sibling.color == RED:
                        sibling.color = BLACK
                        node.parent.color = RED
                        rightRotate(node.parent)
                        sibling = node.parent.left
                    if sibling.left.color == BLACK and sibling.right.color == BLACK:
                        sibling.color = RED
                        node = node.parent
                    else:
                        if sibling.left.color == BLACK:
                            sibling.right.color = BLACK
                            sibling.color = RED
                            leftRotate(sibling)
                            sibling = node.parent.left
                        sibling.color = node.parent.color
                        node.parent.color = BLACK
                        sibling.left.color = BLACK
                        rightRotate(node.parent)
                        node = root
            node.color = BLACK
        ````

        AVL Tree Notes (Detailed)

Trie Notes:
Trie Notes (Detailed)
    1. Definition:
        - A Trie (pronounced "try"), also known as a prefix tree or digital tree, is 
        a tree-like data structure 
        used to store a dynamic set of strings, 
        typically for retrieval by prefix.
        - Each node represents a single character of a string.

    2. Properties:
        - The root node is usually empty and 
        does not correspond to any character.
        - Each edge represents a character.
        - Each path from the root to a node represents 
        a prefix of the stored strings.
        - Nodes may store a flag indicating 
        if they mark the end of a valid word.

    3. Structure:
        - Each node contains:
            * A map or array of child pointers 
            (one for each possible character).
            * A boolean flag (isEndOfWord) 
            to indicate if the node represents the end of a word.

    4. Search Operation:
        - Start at the root.
        - For each character in the search string, 
        follow the corresponding child pointer.
        - If a pointer is missing, 
        the string is not present.
        - If all characters are found and 
        the last node is marked as end of word, 
        the string exists.

        Example (Pseudocode):

        search(root, word):
            node = root
            for char in word:
                if char not in node.children:
                    return False
                node = node.children[char]
            return node.isEndOfWord

    5. Insertion:
        - Start at the root.
        - For each character in the word, create a child node if it does not exist.
        - After the last character, mark the node as end of word.

        Example (Pseudocode):

        insert(root, word):
            node = root
            for char in word:
                if char not in node.children:
                    node.children[char] = new TrieNode()
                node = node.children[char]
            node.isEndOfWord = True

    6. Deletion:
        - Recursively traverse the trie to the end of the word.
        - Unmark the end of word flag.
        - Optionally, remove nodes that are no longer needed (i.e., nodes that are not prefixes of other words).

        Example (Pseudocode):

        delete(node, word, depth=0):
            if depth == len(word):
                if not node.isEndOfWord:
                    return False
                node.isEndOfWord = False
                return len(node.children) == 0
            char = word[depth]
            if char not in node.children:
                return False
            shouldDelete = delete(node.children[char], word, depth+1)
            if shouldDelete:
                del node.children[char]
                return not node.isEndOfWord and len(node.children) == 0
            return False

    7. Complexity:
        - Search: O(L), where L is the length of the word.
        - Insert: O(L)
        - Delete: O(L)
        - Space: O(N * L * A), where N is the number of words, L is average word length, and A is the alphabet size.

    8. Applications:
        - Autocomplete and spell-checking.
        - IP routing (longest prefix matching).
        - Dictionary implementations.
        - Word games and search engines.

    9. Advantages:
        - Fast prefix-based lookups.
        - Efficient for storing large sets of strings with shared prefixes.

    10. Disadvantages:
        - Can use more memory than other data structures (e.g., hash tables) for sparse datasets.
        - Not suitable for non-string or non-prefix-based queries.

    References:
    - "Introduction to Algorithms" by Cormen et al.
    - Wikipedia: https://en.wikipedia.org/wiki/Trie

Example with text diagram:

    Trie Example: Dictionary Words

    Let's insert these words: "CAT", "CAR", "CARD", "CARE", "CAREFUL", "CATS", "DOG"

    Step-by-Step Insertion:

    #1. Insert "CAT":
    ```
        ROOT
        |
        C
        |
        A
        |
        T*
    ```

    #2. Insert "CAR":
    ```
        ROOT
        |
        C
        |
        A
       / \
      T*  R*
    ```

    #3. Insert "CARD":
    ```
        ROOT
        |
        C
        |
        A
       / \
      T*  R*
          |
          D*
    ```

    #4. Insert "CARE":
    ```
        ROOT
        |
        C
        |
        A
       / \
      T*  R*
         / \
        D*  E*
    ```

    #5. Insert "CAREFUL":
    ```
        ROOT
        |
        C
        |
        A
       / \
      T*  R*
         / \
        D*  E*
            |
            F
            |
            U
            |
            L*
    ```

    #6. Insert "CATS":
    ```
        ROOT
         |
         C
         |
         A
        / \
       T*  R*
       |  / \
      S* D* E*
            |
            F
            |
            U
            |
            L*
    ```

    #7. Insert "DOG":
    ```
        ROOT
       /   \
      C     D
      |     |
      A     O
     / \    |
    T*  R*  G*
    |  / \
    S* D* E*
          |
          F
          |
          U
          |
          L*
    ```

    Final Complete Trie Structure:

    ```
        ROOT
       /   \
      C     D
      |     |
      A     O
     / \    |
    T*  R*  G*
    |  / \
    S* D* E*
          |
          F
          |
          U
          |
          L*
    ```

    Legend: `*` = End of word marker (isEndOfWord = true)

    Trie Properties Demonstrated:

    1. Shared Prefixes: "CAR", "CARD", "CARE", "CAREFUL" all share "CAR"
    2. Root is Empty: ROOT node contains no character
    3. Path = Word: Each path from root to `*` represents a complete word
    4. Efficient Storage: Common prefixes stored only once

    Search Examples:

    Search "CAR":
    - ROOT → C → A → R* ✅ (Found, ends with *)

    Search "CARD":
    - ROOT → C → A → R → D* ✅ (Found, ends with *)

    Search "CA":
    - ROOT → C → A ❌ (Not found, no * marker)

    Search "CAMERA":
    - ROOT → C → A → ? ❌ (Path doesn't exist)

    Time Complexity:
    - Search/Insert/Delete: O(L) where L = length of word
    - Space: O(N × L × A) where N = number of words, A = alphabet size

    This Trie efficiently stores 7 words using shared prefixes, demonstrating why it's perfect for autocomplete, spell-checkers, and dictionary implementations!

Trie - Operations
    Trie - Insert Steps:
        1. Start at the root node.
        2. For each character in the word:
            a) If the character does not exist as a child, create a new node.
            b) Move to the child node.
        3. After the last character, mark the node as end of word.

    Trie - Search Steps:
        1. Start at the root node.
        2. For each character in the word:
            a) If the character does not exist as a child, return False.
            b) Move to the child node.
        3. After the last character, return True if the node is marked as end of word.

    Trie - Prefix Search Steps:
        1. Start at the root node.
        2. For each character in the prefix:
            a) If the character does not exist as a child, return False.
            b) Move to the child node.
        3. After the last character, return True (prefix exists).

    Trie - Delete Steps:
        1. Recursively traverse to the end of the word.
        2. Unmark the end of word flag.
        3. Remove nodes that are no longer needed (i.e., not prefixes for other words).

    Summary:
        - Tries are efficient for prefix-based operations and storing dictionaries of words.
        - They support fast insert, search, and prefix queries.
        - Widely used in text processing, autocomplete, and search applications.



B-Tree notes:
B-Tree Notes (Detailed)
    1. Definition:
        - A B-Tree is a self-balancing search tree designed 
        for systems that read and write large blocks of data 
        (e.g., databases, filesystems).
        - Generalizes binary search trees by allowing nodes 
        to have more than two children.
        - Optimized for minimizing disk I/O.

    2. Properties:
        - Each node contains a certain number of keys and children (except leaves).
        - All leaves appear at the same level (tree is balanced).
        - A B-Tree of order t (minimum degree) has:
            * Every node (except root) has at least t-1 keys and at most 2t-1 keys.
            * The root has at least 1 key.
            * Every internal node has at least t children and at most 2t children.
            * Keys within a node are sorted.
            * Children pointers separate the keys into intervals.

    3. Structure:
        - Each node contains:
            * n: number of keys
            * keys[1..n]: sorted array of keys
            * children[0..n]: pointers to child nodes 
            (if not a leaf)
            * leaf: boolean indicating if node is a leaf

    4. Search Operation:
        - Similar to binary search within a node.
        - At each node, perform binary search 
        to find the key or the child to descend into.
        - Time complexity: O(log n)

    5. Insertion:
        - Always insert into a leaf node.
        - If the leaf is full (2t-1 keys), split it:
            * Median key moves up to the parent.
            * Node splits into two nodes with t-1 keys each.
        - If the parent is also full, recursively split up to the root.
        - If the root splits, the tree height increases by 1.

        Example (Pseudocode):

        insert(key):
            if root is full:
                s = new node
                s.leaf = False
                s.children[0] = root
                splitChild(s, 0)
                root = s
            insertNonFull(root, key)

        splitChild(parent, i):
            y = parent.children[i]
            z = new node
            z.leaf = y.leaf
            z.keys = y.keys[t:2t-1]
            if not y.leaf:
                z.children = y.children[t:2t]
            y.keys = y.keys[0:t-1]
            parent.children.insert(i+1, z)
            parent.keys.insert(i, y.keys[t-1])

    6. Deletion:
        - More complex than insertion.
        - If the key is in a leaf, simply remove it.
        - If the key is in an internal node:
            * If the child before or after the key has at least t keys, 
            replace the key with its predecessor or successor and recursively delete.
            * If both children have t-1 keys, merge them and recursively delete.
        - If a child has only t-1 keys, ensure it has at least t keys 
        before descending (by borrowing from siblings or merging).

    7. Complexity:
        - Search: O(log n)
        - Insert: O(log n)
        - Delete: O(log n)
        - Height of B-Tree: O(log_t n), where t is the minimum degree.

    8. Applications:
        - Widely used in databases and filesystems (e.g., MySQL, SQLite, NTFS, ext4).
        - Suitable for storage systems with large blocks/pages.

    9. Advantages:
        - Minimizes disk reads/writes by maximizing branching factor.
        - Maintains balance with minimal restructuring.
        - Efficient for large datasets and external storage.

    10. Disadvantages:
        - More complex implementation than binary search trees.
        - Not as efficient for in-memory data structures with small datasets.

    References:
    - "Introduction to Algorithms" by Cormen et al.
    - Wikipedia: https://en.wikipedia.org/wiki/B-tree

B-Tree - Operations
    B-Tree - Search Steps:
        1. Start at the root node.
        2. For the current node:
            a) Perform binary search among the keys.
            b) If the key is found, return it.
            c) If the node is a leaf and key not found, return null.
            d) Otherwise, descend to the appropriate child and repeat.

        Example (Pseudocode):

        search(node, key):
            i = 0
            while i < node.n and key > node.keys[i]:
                i += 1
            if i < node.n and key == node.keys[i]:
                return (node, i)
            elif node.leaf:
                return null
            else:
                return search(node.children[i], key)

    B-Tree - Insert Steps:
        1. If the root is full, split it and increase the tree height.
        2. Descend to the appropriate child recursively, splitting any full child encountered on the way down.
        3. Insert the key into a non-full leaf node.

        Example (Pseudocode):

        insertNonFull(node, key):
            i = node.n - 1
            if node.leaf:
                node.keys.append(0)
                while i >= 0 and key < node.keys[i]:
                    node.keys[i+1] = node.keys[i]
                    i -= 1
                node.keys[i+1] = key
                node.n += 1
            else:
                while i >= 0 and key < node.keys[i]:
                    i -= 1
                i += 1
                if node.children[i].n == 2*t - 1:
                    splitChild(node, i)
                    if key > node.keys[i]:
                        i += 1
                insertNonFull(node.children[i], key)

    B-Tree - Delete Steps:
        1. Find the key to be deleted.
        2. If the key is in a leaf, remove it.
        3. If the key is in an internal node:
            a) If the child before or after the key has at least t keys, 
            replace the key with its predecessor or successor and recursively delete.
            b) If both children have t-1 keys, merge them and recursively delete.
        4. If descending into a child with t-1 keys, 
        ensure it has at least t keys by borrowing or merging.

        Example (Pseudocode):

        delete(node, key):
            // See Cormen et al. for full details; deletion is complex and involves multiple cases.

    Summary:
        - B-Trees are balanced, multi-way search trees optimized for disk and large block storage.
        - They minimize disk I/O by maximizing the number of keys per node.
        - Used extensively in database and filesystem implementations.